{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c83d6b7",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc3c3",
   "metadata": {},
   "source": [
    "### David Barranquero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bee6615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 15:20:50.333337: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f720f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db9190",
   "metadata": {},
   "source": [
    "Firstly, printing the version of Tensorflow I am working with, should there be any compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73127c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703fc79",
   "metadata": {},
   "source": [
    "Setting a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d29b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = 4760396\n",
    "np.random.seed(random_number)\n",
    "tf.random.set_seed(random_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43c080",
   "metadata": {},
   "source": [
    "For this task, we will be analysing the MAGIC Gamma Telescope dataset which has recorded metrics on gamma rays, and attempts to classify the recorded gamma rays as either gamma, class g, or hadron, class h. The features all relate to the telescopes imaging. The dataset is available at https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a46aa9",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c45cd",
   "metadata": {},
   "source": [
    "We define our class labels and our column/feature labels for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ece774",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['g', 'h']\n",
    "\n",
    "columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym',\n",
    "           'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "\n",
    "feature_columns = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1',\n",
    "                   'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb9b35",
   "metadata": {},
   "source": [
    "Next, we read in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c5ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "magic = pd.read_csv('NNData/magic04.data', header=None)\n",
    "magic.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44efef4",
   "metadata": {},
   "source": [
    "We look at the descriptive statistics for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e27612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19020 entries, 0 to 19019\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   fLength   19020 non-null  float64\n",
      " 1   fWidth    19020 non-null  float64\n",
      " 2   fSize     19020 non-null  float64\n",
      " 3   fConc     19020 non-null  float64\n",
      " 4   fConc1    19020 non-null  float64\n",
      " 5   fAsym     19020 non-null  float64\n",
      " 6   fM3Long   19020 non-null  float64\n",
      " 7   fM3Trans  19020 non-null  float64\n",
      " 8   fAlpha    19020 non-null  float64\n",
      " 9   fDist     19020 non-null  float64\n",
      " 10  class     19020 non-null  object \n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "            fLength        fWidth         fSize         fConc        fConc1  \\\n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
      "mean      53.250154     22.180966      2.825017      0.380327      0.214657   \n",
      "std       42.364855     18.346056      0.472599      0.182813      0.110511   \n",
      "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
      "25%       24.336000     11.863800      2.477100      0.235800      0.128475   \n",
      "50%       37.147700     17.139900      2.739600      0.354150      0.196500   \n",
      "75%       70.122175     24.739475      3.101600      0.503700      0.285225   \n",
      "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
      "\n",
      "              fAsym       fM3Long      fM3Trans        fAlpha         fDist  \n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000  \n",
      "mean      -4.331745     10.545545      0.249726     27.645707    193.818026  \n",
      "std       59.206062     51.000118     20.827439     26.103621     74.731787  \n",
      "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600  \n",
      "25%      -20.586550    -12.842775    -10.849375      5.547925    142.492250  \n",
      "50%        4.013050     15.314100      0.666200     17.679500    191.851450  \n",
      "75%       24.063700     35.837800     10.946425     45.883550    240.563825  \n",
      "max      575.240700    238.321000    179.851000     90.000000    495.561000  \n"
     ]
    }
   ],
   "source": [
    "print(magic.info())\n",
    "print(magic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb421bc9",
   "metadata": {},
   "source": [
    "We can see that there are no missing values in our dataset, and all features are continuous quantitative variables. There is also a large dispersion of value ranges among the features with both positive and negative values.\n",
    "\n",
    "Next, we display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c528ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist class  \n",
      "0  40.0920   81.8828     g  \n",
      "1   6.3609  205.2610     g  \n",
      "2  76.9600  256.7880     g  \n",
      "3  10.4490  116.7370     g  \n",
      "4   4.6480  356.4620     g  \n"
     ]
    }
   ],
   "source": [
    "print(magic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dee586",
   "metadata": {},
   "source": [
    "Furthermore, we look at the distribution of our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9159beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g    12332\n",
      "h     6688\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(magic['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505086f",
   "metadata": {},
   "source": [
    "We can see that there are almost double the amount of observations for class g as there are class h. From this, we would expect better classification performance for class g than class h."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abcd238",
   "metadata": {},
   "source": [
    "Because neural networks can only work with numerical inputs, we are going to create a mapping for our target variable using 0 for g and 1 for h. This also corresponds to their index position in the class labels vector, and will pair up with the sigmoid probabilities later on. We perform the mapping and then print out the first few rows to check that everything has worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c0beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "magic['class'] = magic['class'].map({'g': 0, 'h': 1})\n",
    "\n",
    "print(magic['class'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a660cd0",
   "metadata": {},
   "source": [
    "For splitting our dataset, we will perform stratified sampling via proportional allocation. This will mean that our training and test datasets will have the same class distributions as the original dataset. Stratified sampling is best performed when the mean response of the different groups in the strata are very different, and has the effect of achieving a lower sampling variance, the variance of all the possible samples I could take with a particular sampling design, when compared to simple random sampling. We perform the sampling as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2436f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use proportional allocation to perform the Stratified Sampling\n",
    "# First we separate all the values of the data\n",
    "magic_g = magic.index[magic['class'] == 0].tolist()\n",
    "magic_h = magic.index[magic['class'] == 1].tolist()\n",
    "\n",
    "# And store these in a list\n",
    "target_classes = [magic_g, magic_h]\n",
    "\n",
    "# Our function to split the records into training and test,\n",
    "def split_train_test(df, test_ratio):\n",
    "    training_idx_full = []\n",
    "    test_idx_full = []\n",
    "    for i in range(0, 2):  # We perform this random sampling for each stratum, labels of the target variable\n",
    "        training_idx, test_idx = shuffle_and_split(target_classes[i], len(target_classes[i]), test_ratio)\n",
    "        training_idx_full.extend(training_idx)\n",
    "        test_idx_full.extend(test_idx)\n",
    "\n",
    "    return df.iloc[training_idx_full].copy(), df.iloc[test_idx_full].copy()\n",
    "\n",
    "\n",
    "# Our function to decide which rows will be for the test data set\n",
    "def shuffle_and_split(indices, length, test_ratio):\n",
    "    np.random.shuffle(indices)\n",
    "    test_set_size = round(length * test_ratio)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3707b6a",
   "metadata": {},
   "source": [
    "We call our function to get the training and test datasets.\n",
    "Our specification requires a 70/30 train/test split. Later, we will also use 10% of the training data for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c86490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = split_train_test(magic, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9828f",
   "metadata": {},
   "source": [
    "Next, we will validate that our stratified sampling was performed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc72f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proportion of data in Training set: 0.7\n",
      "Proportion of data in Test set: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks on data size\n",
    "print('\\nProportion of data in Training set:', \n",
    "      round(len(training_data) / len(magic), 4))\n",
    "\n",
    "print('Proportion of data in Test set:', \n",
    "      round(len(test_data) / len(magic), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9855944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training Strat  Test Strat  Original DF  Training Diff  Test Diff\n",
      "0         0.64834     0.64844      0.64837       -0.00003    0.00007\n",
      "1         0.35166     0.35156      0.35163        0.00003   -0.00007\n"
     ]
    }
   ],
   "source": [
    "# Calculating how well our Stratified Sampler performed\n",
    "training_prop = training_data['class'].value_counts() / len(training_data)\n",
    "test_prop = test_data['class'].value_counts() / len(test_data)\n",
    "original_prop = magic['class'].value_counts() / len(magic)\n",
    "\n",
    "# Build a DF containing the performance stats\n",
    "strat_stats = pd.DataFrame({\n",
    "    \"Training Strat\": training_prop,\n",
    "    \"Test Strat\": test_prop,\n",
    "    \"Original DF\": original_prop,\n",
    "    \"Training Diff\": training_prop - original_prop,\n",
    "    \"Test Diff\": test_prop - original_prop\n",
    "}).sort_index()\n",
    "\n",
    "# Display the stats\n",
    "print(strat_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec433284",
   "metadata": {},
   "source": [
    "Next, we create the design matrices for our training and test datasets and remove the target variable from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c61961",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training_data['class'].to_numpy()\n",
    "training_data = training_data.drop('class', axis=1)\n",
    "X_train = training_data.to_numpy()\n",
    "\n",
    "y_test = test_data['class'].to_numpy()\n",
    "test_data = test_data.drop('class', axis=1)\n",
    "X_test = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058fa5b",
   "metadata": {},
   "source": [
    "Neural networks perform best when some form of normalisation or standardisation is performed on the feature inputs. Scaling all features will lead to faster convergence of the gradient to a local minimum. We will use Min-Max Normalisation to shrink all values to within the 0 and 1 range, while preserving the distributional shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1e14e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - np.min(X_train, axis=0)) / (np.max(X_train, axis=0) - np.min(X_train, axis=0))\n",
    "\n",
    "X_test = (X_test - np.min(X_test, axis=0)) / (np.max(X_test, axis=0) - np.min(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630f15b",
   "metadata": {},
   "source": [
    "Checking that the minimum value is 0 and maximum value is 1 for both datasets for each feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8941a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Min: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Max: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Test Min: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Test Max: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Train Min:', np.min(X_train, axis=0))\n",
    "print('Train Max:', np.max(X_train, axis=0))\n",
    "\n",
    "print('Test Min:', np.min(X_test, axis=0))\n",
    "print('Test Max:', np.max(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd52c4",
   "metadata": {},
   "source": [
    "Next, we will take 10 percent from our training dataset to use for the validation set. Our dataset is presented with all 'g' targets first, and then all 'h' targets. So just taking from the top or tail of the dataset will result in only one class of variables to validate with. So we will take a class proportional amount from the top and tail, to be consistent with our previous stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bcbdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows are we going to take in total\n",
    "valid_size = round(X_train.shape[0] * 0.1)\n",
    "\n",
    "# We calculate the index of how many 'g' rows to take.\n",
    "first_part = round(valid_size * original_prop[0])\n",
    "\n",
    "# And the index of how many 'h' rows to take.\n",
    "second_part = len(X_train) - round(valid_size * original_prop[1])\n",
    "\n",
    "# We take from the top and tail from both the features and the target\n",
    "X_1, X_train, X_2 = X_train[:first_part], X_train[first_part:second_part], X_train[second_part:]\n",
    "y_1, y_train, y_2 = y_train[:first_part], y_train[first_part:second_part], y_train[second_part:]\n",
    "\n",
    "# Then vertically stack the features and horizontally stack the targets (as its a 1D array)\n",
    "X_valid = np.vstack((X_1, X_2))\n",
    "y_valid = np.hstack((y_1, y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626fe33",
   "metadata": {},
   "source": [
    "We now print out the shapes of each dataset, to ensure everything is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38cc8907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11983, 10)\n",
      "(11983,)\n",
      "(1331, 10)\n",
      "(1331,)\n",
      "(5706, 10)\n",
      "(5706,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e75695",
   "metadata": {},
   "source": [
    "## Creating Our Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb617e3",
   "metadata": {},
   "source": [
    "Now that the pre-processing is complete, we are ready to build our neural network. Generally, better performance on neural networks can be achieved by building a network that has fewer parameters and more layers. This is because it can reduce overparameterising our model and overfitting to our training data, but also by more layers, we promote the feature construction by the network in identifying lines and shapes, then features, then the object. As a starting point, we will construct an initial network with 3 hidden layers and 50 neurons, as an educated guess of what will produce a good classification model.\n",
    "\n",
    "The input layer can be specified in the first hidden layer using the input_dim parameter. Here we specify that the input is 10 feature columns. We will be using the ReLU activation function for our hidden layers, where ReLU(a) = max(0,a). ReLU is commonly used in state-of-the-art deep learning technologies, such as facial recognition technology, as it eliminates the vanishing/exploding gradient of earlier activations such as the sigmoid activation, as the derivative of ReLU for positive values is 1, avoiding small number multiplications through the chain rule when calculating the gradient of the loss function. Furthermore ReLU also promotes sparsity by setting negatively activated neurons to 0, leading to faster calculations and gradient convergence. \n",
    "\n",
    "Because we are performing binary classificaton, we will just have one neuron in the final layer, which produces a probability of the positive class. The sigmoid function, which maps the real number line to the (0,1) interval, is most commonly used in logistic regression in modelling the log-odds of a binary target variable. Given how we have coded our classes as 0 or 1 and indexed the labels, a probability closer to 0 indicates the 0 mapped class which is at index 0 of the labels, so class 'g'. A probability closer to 1 is the opposite, we predict class 'h'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0e96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 15:21:01.517317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, input_dim=10, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c6035",
   "metadata": {},
   "source": [
    "With regards to the model summary, we can see the number of parameters (weights and biases) in each layer. So our first layer has 10 input features, 10 weights per feature plus 1 bias per neuron for 50 neurons, so 550 parameters in total.\n",
    "\n",
    "We can view the dimensions of these weights and biases as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "214060ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "weights, biases = model.layers[0].get_weights()\n",
    "\n",
    "print(weights.shape)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d4a1c",
   "metadata": {},
   "source": [
    "Now that we have constructed our model, we need to compile it. For our gradient optimiser, we will use stochastic gradient descent (SGD). Rather than performing the back-propagation to train a neural network on the entire dataset, which is computationally intensive and time consuming, we will only use a sample of our data. This leads to faster, more imprecise steps towards to gradient functions local minimum, rather than slower, more calculated steps. As an added advantage, the imprecision of the steps can lead to us overshooting the descent, and leaving the local minima region towards the global minima.\n",
    "\n",
    "Our loss function will be binary cross-entropy, as we are performing binary classification on with our model. Furthermore as this is a classification problem, this means that our performance metric will be accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e471440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a8c8f",
   "metadata": {},
   "source": [
    "Finally, we fit our model to the training data. As in the lab, we will use 15 epochs, or sweeps over the entire data in our training. We will also use our validation dataset to assess the model fit, and detect any overfitting that may occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b585444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.6374 - accuracy: 0.6500 - val_loss: 0.6090 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.6980 - val_loss: 0.5529 - val_accuracy: 0.7355\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7582 - val_loss: 0.5065 - val_accuracy: 0.7618\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7748 - val_loss: 0.4846 - val_accuracy: 0.7829\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7874 - val_loss: 0.4675 - val_accuracy: 0.7874\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.7965 - val_loss: 0.4541 - val_accuracy: 0.7994\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8021 - val_loss: 0.4460 - val_accuracy: 0.7956\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8066 - val_loss: 0.4306 - val_accuracy: 0.8069\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.8105 - val_loss: 0.4216 - val_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4109 - accuracy: 0.8157 - val_loss: 0.4169 - val_accuracy: 0.8152\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "fitted_model = model.fit(X_train, y_train, epochs=n_epochs, \n",
    "                         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24fbdc6",
   "metadata": {},
   "source": [
    "We can visualise the training accuracy and loss, as well as that of the validation set via a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f347a690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(fitted_model.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62af7bd",
   "metadata": {},
   "source": [
    "From this plot, we can observe strong model performance. With the successive sweeps over the dataset, our models training accuracy has continued to rise, and the loss has continued to decrease, which indicates that our model is updating the weights and biases in a correct manner. \n",
    "\n",
    "Furthermore, the validation accuracy and loss is close to that of the training set. If our model was overfitting, we would expect to see strong training accuracy, but poor validation accuracy, as our model fits too closely to the noise of individual observations and does not generalise well. As this is not observed, this is a good thing and suggests our model is NOT overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe54c67",
   "metadata": {},
   "source": [
    "Next, we will evaluate the models performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d84f8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8214\n",
      "[0.4149346947669983, 0.8214160799980164]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78247d6",
   "metadata": {},
   "source": [
    "Overall, this is a strong test accuracy for our model, and indicates a strong overall classification ability.\n",
    "\n",
    "Before we begin fine-tuning the model, we want to ensure that the model is behaving correctly and producing valid output. There is no point trying to optimise a model which is not giving valid output. We will assess the predictions for both some observations from class g and some from class h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6149141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Predicted: [0. 0. 0.]\n",
      "True:  [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Let's try predicting some 'g' classes\n",
    "X_new = X_test[:3]\n",
    "y_prob = model.predict(X_new)\n",
    "y_pred = np.round([y_prob[0][0], y_prob[1][0], y_prob[2][0]])\n",
    "print('Predicted:', y_pred)\n",
    "print('True: ', y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb357a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted: [0. 0. 1.]\n",
      "True:  [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# And now some 'h' classes\n",
    "X_new = X_test[-3:]\n",
    "y_prob = model.predict(X_new)\n",
    "y_pred = np.round([y_prob[0][0], y_prob[1][0], y_prob[2][0]])\n",
    "print('Predicted:', y_pred)\n",
    "print('True: ', y_test[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0469973",
   "metadata": {},
   "source": [
    "As we can see, our model is producing valid output. In this little sample, we are also performing better at classifying the 'g' class than the 'h' class. This is likely an effect of 'g' having almost double the observations as 'h' in the training dataset, and so we are observing better classification performance for 'g'.\n",
    "\n",
    "Next, we will move onto hyperparameter fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f70e25",
   "metadata": {},
   "source": [
    "## Fine-Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672b7f4",
   "metadata": {},
   "source": [
    "To fine-tune our hyperparameters for our model, we will be performing grid search via cross-validation. We will be wrapping the code we used to implement our model in a function and then wrapping this in a KerasClassifier wrapper so that we can use the Scikit Learn GridSearchCV function with our keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ddd7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/3vhcqh5j54n5rh_ffnt1jks80000gn/T/ipykernel_98751/3954053308.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden, n_neurons):\n",
    "    print('\\nn_hidden={0}, n_neurons={1}'\n",
    "          .format(n_hidden, n_neurons))\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(n_neurons, input_dim=10, activation='relu'))\n",
    "    for _ in range(n_hidden - 1):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='SGD', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "keras_classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4b7049",
   "metadata": {},
   "source": [
    "With regards to the hyperparameter grid to trial, we will be trialing two different components. Firstly, the number of hidden layers, we will trial both our three hidden layer model, and a deeper 4 hidden layer model. We will also test to see what the optimal number of neurons is. Again we have our default amount from the previous model, and also double the amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e504b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_try = {\n",
    "    'n_hidden': [3, 4],\n",
    "    'n_neurons': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb1cf7",
   "metadata": {},
   "source": [
    "We are also going to include a callback with a patience of 5. This is used to stop training early if we observe the loss begin to rise, or accuracy begin to decrease, suggesting we have reached either a minumum or maximum respectively. The patience of 5 means we wait for 5 epochs without change before halting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963c56e",
   "metadata": {},
   "source": [
    "In total, we have two parameters with two possible values, hence 2x2 = 4 possible combinations. This combined with 5-fold cross validation, and 10 epochs, with a 1 second training time per epoch suggests a 4x5x10/60 = 3.33 minute optimisation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53b481ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hidden=3, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6770 - accuracy: 0.5610 - val_loss: 0.6408 - val_accuracy: 0.6514\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6450 - accuracy: 0.6393 - val_loss: 0.6040 - val_accuracy: 0.7318\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.7166 - val_loss: 0.5596 - val_accuracy: 0.7588\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7510 - val_loss: 0.5155 - val_accuracy: 0.7746\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7639 - val_loss: 0.4902 - val_accuracy: 0.7866\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7719 - val_loss: 0.4876 - val_accuracy: 0.7934\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4802 - accuracy: 0.7788 - val_loss: 0.4606 - val_accuracy: 0.7934\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7817 - val_loss: 0.4460 - val_accuracy: 0.7949\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.7849 - val_loss: 0.4405 - val_accuracy: 0.7971\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7879 - val_loss: 0.4415 - val_accuracy: 0.7941\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8519\n",
      "\n",
      "n_hidden=3, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6831 - accuracy: 0.5587 - val_loss: 0.6562 - val_accuracy: 0.6499\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.6435 - val_loss: 0.6242 - val_accuracy: 0.7355\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.7252 - val_loss: 0.5819 - val_accuracy: 0.7686\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5654 - accuracy: 0.7527 - val_loss: 0.5338 - val_accuracy: 0.7806\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.7643 - val_loss: 0.4998 - val_accuracy: 0.7829\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7686 - val_loss: 0.4939 - val_accuracy: 0.7949\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4957 - accuracy: 0.7748 - val_loss: 0.4771 - val_accuracy: 0.7934\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7768 - val_loss: 0.4630 - val_accuracy: 0.7926\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7796 - val_loss: 0.4566 - val_accuracy: 0.7934\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.7817 - val_loss: 0.4596 - val_accuracy: 0.7926\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8661\n",
      "\n",
      "n_hidden=3, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 3ms/step - loss: 0.6688 - accuracy: 0.5717 - val_loss: 0.6340 - val_accuracy: 0.6597\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6358 - accuracy: 0.6513 - val_loss: 0.5980 - val_accuracy: 0.7137\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5931 - accuracy: 0.7150 - val_loss: 0.5591 - val_accuracy: 0.7536\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7434 - val_loss: 0.5218 - val_accuracy: 0.7739\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7609 - val_loss: 0.4974 - val_accuracy: 0.7806\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7676 - val_loss: 0.4965 - val_accuracy: 0.7889\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4890 - accuracy: 0.7753 - val_loss: 0.4710 - val_accuracy: 0.7926\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7770 - val_loss: 0.4575 - val_accuracy: 0.7956\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4694 - accuracy: 0.7817 - val_loss: 0.4502 - val_accuracy: 0.7971\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7835 - val_loss: 0.4470 - val_accuracy: 0.7956\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8544\n",
      "\n",
      "n_hidden=3, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5760 - accuracy: 0.7479 - val_loss: 0.6316 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7501 - val_loss: 0.5974 - val_accuracy: 0.6529\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7730 - val_loss: 0.5648 - val_accuracy: 0.7062\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4513 - accuracy: 0.8007 - val_loss: 0.5391 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8103 - val_loss: 0.5159 - val_accuracy: 0.7528\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4211 - accuracy: 0.8163 - val_loss: 0.5108 - val_accuracy: 0.7596\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.8202 - val_loss: 0.4934 - val_accuracy: 0.7701\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8223 - val_loss: 0.4793 - val_accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4015 - accuracy: 0.8271 - val_loss: 0.4924 - val_accuracy: 0.7716\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8318 - val_loss: 0.4729 - val_accuracy: 0.7814\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7422 - accuracy: 0.6035\n",
      "\n",
      "n_hidden=3, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5438 - accuracy: 0.7900 - val_loss: 0.6779 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.8104 - val_loss: 0.6899 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8104 - val_loss: 0.6700 - val_accuracy: 0.6484\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8104 - val_loss: 0.6451 - val_accuracy: 0.6484\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8122 - val_loss: 0.6042 - val_accuracy: 0.6634\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8336 - val_loss: 0.5791 - val_accuracy: 0.7107\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8460 - val_loss: 0.5608 - val_accuracy: 0.7400\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8530 - val_loss: 0.5371 - val_accuracy: 0.7483\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8579 - val_loss: 0.5532 - val_accuracy: 0.7431\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8611 - val_loss: 0.5157 - val_accuracy: 0.7648\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1442 - accuracy: 0.4044\n",
      "\n",
      "n_hidden=3, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6797 - accuracy: 0.5482 - val_loss: 0.6499 - val_accuracy: 0.6431\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6508 - accuracy: 0.6393 - val_loss: 0.6198 - val_accuracy: 0.7047\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.7078 - val_loss: 0.5809 - val_accuracy: 0.7528\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7383 - val_loss: 0.5353 - val_accuracy: 0.7686\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7552 - val_loss: 0.4991 - val_accuracy: 0.7769\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.7683 - val_loss: 0.4938 - val_accuracy: 0.7919\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7777 - val_loss: 0.4683 - val_accuracy: 0.7889\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7802 - val_loss: 0.4517 - val_accuracy: 0.7911\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.7845 - val_loss: 0.4446 - val_accuracy: 0.7964\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7890 - val_loss: 0.4452 - val_accuracy: 0.7971\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8515\n",
      "\n",
      "n_hidden=3, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6705 - accuracy: 0.5986 - val_loss: 0.6372 - val_accuracy: 0.7002\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6298 - accuracy: 0.6987 - val_loss: 0.5902 - val_accuracy: 0.7393\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5757 - accuracy: 0.7395 - val_loss: 0.5420 - val_accuracy: 0.7746\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5292 - accuracy: 0.7594 - val_loss: 0.5073 - val_accuracy: 0.7799\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7688 - val_loss: 0.4857 - val_accuracy: 0.7866\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4915 - accuracy: 0.7701 - val_loss: 0.4855 - val_accuracy: 0.7934\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.7751 - val_loss: 0.4662 - val_accuracy: 0.7919\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7782 - val_loss: 0.4542 - val_accuracy: 0.7889\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7788 - val_loss: 0.4472 - val_accuracy: 0.7911\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.7807 - val_loss: 0.4493 - val_accuracy: 0.7911\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8481\n",
      "\n",
      "n_hidden=3, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6697 - accuracy: 0.5822 - val_loss: 0.6387 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.6515 - val_loss: 0.6039 - val_accuracy: 0.7130\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5938 - accuracy: 0.7199 - val_loss: 0.5595 - val_accuracy: 0.7581\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7488 - val_loss: 0.5175 - val_accuracy: 0.7776\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.7642 - val_loss: 0.4877 - val_accuracy: 0.7851\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4902 - accuracy: 0.7719 - val_loss: 0.4810 - val_accuracy: 0.7956\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.7762 - val_loss: 0.4592 - val_accuracy: 0.7949\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7810 - val_loss: 0.4452 - val_accuracy: 0.8002\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7857 - val_loss: 0.4381 - val_accuracy: 0.8002\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.7890 - val_loss: 0.4362 - val_accuracy: 0.7994\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8577\n",
      "\n",
      "n_hidden=3, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5743 - accuracy: 0.7501 - val_loss: 0.6513 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7501 - val_loss: 0.6225 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7505 - val_loss: 0.5889 - val_accuracy: 0.6582\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.7800 - val_loss: 0.5550 - val_accuracy: 0.7107\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4404 - accuracy: 0.8068 - val_loss: 0.5220 - val_accuracy: 0.7453\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8151 - val_loss: 0.5103 - val_accuracy: 0.7596\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8226 - val_loss: 0.4873 - val_accuracy: 0.7739\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8271 - val_loss: 0.4702 - val_accuracy: 0.7791\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8319 - val_loss: 0.4810 - val_accuracy: 0.7784\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8365 - val_loss: 0.4598 - val_accuracy: 0.7851\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.6181\n",
      "\n",
      "n_hidden=3, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5121 - accuracy: 0.8100 - val_loss: 0.6910 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8104 - val_loss: 0.6600 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8104 - val_loss: 0.6251 - val_accuracy: 0.6484\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3995 - accuracy: 0.8240 - val_loss: 0.5963 - val_accuracy: 0.6942\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3775 - accuracy: 0.8417 - val_loss: 0.5550 - val_accuracy: 0.7310\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8474 - val_loss: 0.5482 - val_accuracy: 0.7385\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8503 - val_loss: 0.5431 - val_accuracy: 0.7461\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8546 - val_loss: 0.5167 - val_accuracy: 0.7603\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8583 - val_loss: 0.5464 - val_accuracy: 0.7536\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8605 - val_loss: 0.5035 - val_accuracy: 0.7724\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.1104 - accuracy: 0.4232\n",
      "\n",
      "n_hidden=4, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6803 - accuracy: 0.5604 - val_loss: 0.6519 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6641 - accuracy: 0.5709 - val_loss: 0.6294 - val_accuracy: 0.6732\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6326 - accuracy: 0.6651 - val_loss: 0.5905 - val_accuracy: 0.7438\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5780 - accuracy: 0.7345 - val_loss: 0.5322 - val_accuracy: 0.7686\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7622 - val_loss: 0.4951 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5000 - accuracy: 0.7719 - val_loss: 0.4986 - val_accuracy: 0.7896\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7762 - val_loss: 0.4644 - val_accuracy: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7809 - val_loss: 0.4514 - val_accuracy: 0.7889\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7817 - val_loss: 0.4429 - val_accuracy: 0.7896\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7858 - val_loss: 0.4393 - val_accuracy: 0.7949\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8352\n",
      "\n",
      "n_hidden=4, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.5604 - val_loss: 0.6468 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6556 - accuracy: 0.5920 - val_loss: 0.6150 - val_accuracy: 0.7062\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.6908 - val_loss: 0.5714 - val_accuracy: 0.7506\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7362 - val_loss: 0.5246 - val_accuracy: 0.7678\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7570 - val_loss: 0.4926 - val_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7684 - val_loss: 0.4872 - val_accuracy: 0.7956\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.7767 - val_loss: 0.4562 - val_accuracy: 0.7964\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7827 - val_loss: 0.4384 - val_accuracy: 0.7941\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.7858 - val_loss: 0.4275 - val_accuracy: 0.8017\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.4206 - val_accuracy: 0.8024\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8615\n",
      "\n",
      "n_hidden=4, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6770 - accuracy: 0.5604 - val_loss: 0.6452 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6571 - accuracy: 0.5870 - val_loss: 0.6169 - val_accuracy: 0.6950\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.6916 - val_loss: 0.5757 - val_accuracy: 0.7588\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.7435 - val_loss: 0.5268 - val_accuracy: 0.7746\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7604 - val_loss: 0.4964 - val_accuracy: 0.7851\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7688 - val_loss: 0.4941 - val_accuracy: 0.7866\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7736 - val_loss: 0.4600 - val_accuracy: 0.7926\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7781 - val_loss: 0.4437 - val_accuracy: 0.7941\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.7824 - val_loss: 0.4330 - val_accuracy: 0.7971\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.7851 - val_loss: 0.4301 - val_accuracy: 0.7994\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8306\n",
      "\n",
      "n_hidden=4, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5940 - accuracy: 0.7387 - val_loss: 0.6499 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7501 - val_loss: 0.6279 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7505 - val_loss: 0.5886 - val_accuracy: 0.6551\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7822 - val_loss: 0.5369 - val_accuracy: 0.7107\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8054 - val_loss: 0.4991 - val_accuracy: 0.7528\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8198 - val_loss: 0.4928 - val_accuracy: 0.7648\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8247 - val_loss: 0.4780 - val_accuracy: 0.7761\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8308 - val_loss: 0.4562 - val_accuracy: 0.7904\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8326 - val_loss: 0.4739 - val_accuracy: 0.7814\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3821 - accuracy: 0.8347 - val_loss: 0.4582 - val_accuracy: 0.7821\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7275 - accuracy: 0.6139\n",
      "\n",
      "n_hidden=4, n_neurons=50\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5223 - accuracy: 0.8026 - val_loss: 0.7027 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.8104 - val_loss: 0.6885 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8104 - val_loss: 0.6599 - val_accuracy: 0.6484\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8105 - val_loss: 0.6239 - val_accuracy: 0.6544\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3905 - accuracy: 0.8319 - val_loss: 0.5636 - val_accuracy: 0.7243\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8477 - val_loss: 0.5535 - val_accuracy: 0.7363\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.8526 - val_loss: 0.5550 - val_accuracy: 0.7438\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3519 - accuracy: 0.8565 - val_loss: 0.5154 - val_accuracy: 0.7626\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8615 - val_loss: 0.5568 - val_accuracy: 0.7551\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8622 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0956 - accuracy: 0.4341\n",
      "\n",
      "n_hidden=4, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6692 - accuracy: 0.5721 - val_loss: 0.6293 - val_accuracy: 0.6747\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6236 - accuracy: 0.6845 - val_loss: 0.5739 - val_accuracy: 0.7385\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7378 - val_loss: 0.5273 - val_accuracy: 0.7739\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.7600 - val_loss: 0.4969 - val_accuracy: 0.7866\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4964 - accuracy: 0.7721 - val_loss: 0.4683 - val_accuracy: 0.7889\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7816 - val_loss: 0.4763 - val_accuracy: 0.7971\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4621 - accuracy: 0.7827 - val_loss: 0.4382 - val_accuracy: 0.7956\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4486 - accuracy: 0.7900 - val_loss: 0.4235 - val_accuracy: 0.8077\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4370 - accuracy: 0.7919 - val_loss: 0.4174 - val_accuracy: 0.8077\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.7994 - val_loss: 0.4187 - val_accuracy: 0.7949\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8552\n",
      "\n",
      "n_hidden=4, n_neurons=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6712 - accuracy: 0.5972 - val_loss: 0.6361 - val_accuracy: 0.6905\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6291 - accuracy: 0.6919 - val_loss: 0.5818 - val_accuracy: 0.7363\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7409 - val_loss: 0.5290 - val_accuracy: 0.7769\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7610 - val_loss: 0.4952 - val_accuracy: 0.7874\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.7728 - val_loss: 0.4654 - val_accuracy: 0.7956\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7796 - val_loss: 0.4622 - val_accuracy: 0.8024\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7818 - val_loss: 0.4379 - val_accuracy: 0.7994\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.7884 - val_loss: 0.4227 - val_accuracy: 0.8084\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.7923 - val_loss: 0.4160 - val_accuracy: 0.8099\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4311 - accuracy: 0.7965 - val_loss: 0.4199 - val_accuracy: 0.7986\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8444\n",
      "\n",
      "n_hidden=4, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6797 - accuracy: 0.5549 - val_loss: 0.6526 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6600 - accuracy: 0.5922 - val_loss: 0.6283 - val_accuracy: 0.6912\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6252 - accuracy: 0.6943 - val_loss: 0.5880 - val_accuracy: 0.7498\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5671 - accuracy: 0.7435 - val_loss: 0.5308 - val_accuracy: 0.7731\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7631 - val_loss: 0.4958 - val_accuracy: 0.7851\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.7723 - val_loss: 0.4930 - val_accuracy: 0.7949\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7775 - val_loss: 0.4649 - val_accuracy: 0.7956\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.7797 - val_loss: 0.4499 - val_accuracy: 0.7934\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7839 - val_loss: 0.4418 - val_accuracy: 0.7964\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7876 - val_loss: 0.4347 - val_accuracy: 0.8039\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8753\n",
      "\n",
      "n_hidden=4, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5926 - accuracy: 0.7476 - val_loss: 0.6539 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7501 - val_loss: 0.6424 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7501 - val_loss: 0.6088 - val_accuracy: 0.6484\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7589 - val_loss: 0.5667 - val_accuracy: 0.6882\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8025 - val_loss: 0.5242 - val_accuracy: 0.7461\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8166 - val_loss: 0.5080 - val_accuracy: 0.7648\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8251 - val_loss: 0.4808 - val_accuracy: 0.7799\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8326 - val_loss: 0.4581 - val_accuracy: 0.7904\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3847 - accuracy: 0.8383 - val_loss: 0.4644 - val_accuracy: 0.7851\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3774 - accuracy: 0.8448 - val_loss: 0.4497 - val_accuracy: 0.7889\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.6156\n",
      "\n",
      "n_hidden=4, n_neurons=100\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5220 - accuracy: 0.8072 - val_loss: 0.6843 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8104 - val_loss: 0.6619 - val_accuracy: 0.6484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8105 - val_loss: 0.6175 - val_accuracy: 0.6559\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.8303 - val_loss: 0.5881 - val_accuracy: 0.7077\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8468 - val_loss: 0.5314 - val_accuracy: 0.7476\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8550 - val_loss: 0.5272 - val_accuracy: 0.7551\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8612 - val_loss: 0.5253 - val_accuracy: 0.7611\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8665 - val_loss: 0.4909 - val_accuracy: 0.7799\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8711 - val_loss: 0.5345 - val_accuracy: 0.7671\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8734 - val_loss: 0.4691 - val_accuracy: 0.7911\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 1.0183 - accuracy: 0.4558\n",
      "\n",
      "n_hidden=4, n_neurons=100\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.6381 - accuracy: 0.6446 - val_loss: 0.6091 - val_accuracy: 0.6484\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.6968 - val_loss: 0.5410 - val_accuracy: 0.7273\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.7612 - val_loss: 0.4924 - val_accuracy: 0.7724\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4726 - accuracy: 0.7848 - val_loss: 0.4683 - val_accuracy: 0.7934\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.7966 - val_loss: 0.4490 - val_accuracy: 0.7941\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4317 - accuracy: 0.8039 - val_loss: 0.4366 - val_accuracy: 0.7956\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8104 - val_loss: 0.4236 - val_accuracy: 0.8069\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8167 - val_loss: 0.4063 - val_accuracy: 0.8159\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8224 - val_loss: 0.3977 - val_accuracy: 0.8219\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8257 - val_loss: 0.4089 - val_accuracy: 0.8114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d597c16d0&gt;,\n",
       "             param_grid={&#x27;n_hidden&#x27;: [3, 4], &#x27;n_neurons&#x27;: [50, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d597c16d0&gt;,\n",
       "             param_grid={&#x27;n_hidden&#x27;: [3, 4], &#x27;n_neurons&#x27;: [50, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d597c16d0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d597c16d0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d597c16d0>,\n",
       "             param_grid={'n_hidden': [3, 4], 'n_neurons': [50, 100]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(keras_classifier, params_to_try, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, \n",
    "                y_train, \n",
    "                epochs=n_epochs, \n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faa15b9",
   "metadata": {},
   "source": [
    "After optimisation, we observe that our best model parameters are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c63bf968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden': 4, 'n_neurons': 100}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981a2b4",
   "metadata": {},
   "source": [
    "These parameters produced the optimal cross validated accuracy on the validation set of,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73618ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7292508482933044\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d284801",
   "metadata": {},
   "source": [
    "We can save this model in a variable, and display the network structure as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75c019e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,501\n",
      "Trainable params: 31,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_.model\n",
    "\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7be39",
   "metadata": {},
   "source": [
    "Finally, we display the test accuracy of our optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c611a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8342\n",
      "[0.39470264315605164, 0.8342096209526062]\n"
     ]
    }
   ],
   "source": [
    "print(best_model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1934f38",
   "metadata": {},
   "source": [
    "While this is only a slight improvement, it has resulted in a neural network with higher classification accuracy. With regards to our original dataset, this means that we are able to better distinguish between the gamma rays as either gamma or hadron."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
